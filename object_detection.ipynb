{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb80a042-8c90-4c97-a2ef-044c4bf708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687d8e6f-0732-442b-90ef-223430692d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pre-trained VGG16 model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 1: Load the Pre-trained CNN Model (VGG16 without top)\n",
    "# ==========================================================\n",
    "base = VGG16(\n",
    "    weights=r'C:\\assignement\\sem7\\dataset\\Object Detection(Ass6)\\vgg16_weights.h5',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "print(\"âœ… Pre-trained VGG16 model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae608289-c9af-4c6d-bd80-668ba975985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Freeze base model ----\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cadf8fa-d9b8-4505-9455-eb69452856f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a66c1c-3eca-4952-b62d-61edbf980f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 674 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "selected_classes = ['airplanes', 'ant']\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    r\"C:\\assignement\\sem7\\dataset\\Object Detection(Ass6)\\caltech-101-img\", target_size=(224,224),\n",
    "    batch_size=32, subset='training', classes=selected_classes\n",
    ")\n",
    "\n",
    "val_data = train_gen.flow_from_directory(\n",
    "    r\"C:\\assignement\\sem7\\dataset\\Object Detection(Ass6)\\caltech-101-img\", target_size=(224,224),\n",
    "    batch_size=32, subset='validation', classes=selected_classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e385a235-3eb0-42de-81eb-5b401a4c5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Add Classifier on top of base model ----\n",
    "model = Sequential([\n",
    "    base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# ---- Compile (train only new layers) ----\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1161b36b-6a1f-434a-91dd-14fff2cdb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.9421 - loss: 0.3566 - val_accuracy: 0.9762 - val_loss: 0.0485\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 6s/step - accuracy: 0.9941 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 5.0456e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 2.5683e-06\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 7s/step - accuracy: 0.9985 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 4.2953e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 9s/step - accuracy: 0.9970 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 4.0446e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a809879d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---- Train ----\n",
    "model.fit(train_data, validation_data=val_data, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33c4d42-e61b-47cd-a188-eec55ccc218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Fine-tuning top layers...\n",
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 2.9464e-04 - val_accuracy: 1.0000 - val_loss: 2.7531e-07\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 7s/step - accuracy: 0.9985 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 4.2369e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 7.2887e-06 - val_accuracy: 1.0000 - val_loss: 1.7363e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 2.0353e-04 - val_accuracy: 1.0000 - val_loss: 2.3345e-07\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 3.9616e-05 - val_accuracy: 1.0000 - val_loss: 4.2575e-09\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 4.2575e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Final Validation Accuracy: 100.00%\n",
      "âœ… Model saved successfully as vgg16_transfer_learning_final.h5\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Step 7: Fine-tune (unfreeze top layers)\n",
    "# ==========================================================\n",
    "# Unfreeze last 4 convolutional layers\n",
    "for layer in base.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile with smaller learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"ğŸ”„ Fine-tuning top layers...\")\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# Step 8: Evaluate and Save the model\n",
    "# ==========================================================\n",
    "loss, acc = model.evaluate(val_data)\n",
    "print(f\"\\nâœ… Final Validation Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "model.save(\"vgg16_transfer_learning_final.h5\")\n",
    "print(\"âœ… Model saved successfully as vgg16_transfer_learning_final.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
